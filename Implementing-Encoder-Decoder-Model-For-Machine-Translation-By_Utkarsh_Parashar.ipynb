{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwPL0hIlGKoA"
   },
   "source": [
    "# <font color='red'>**Sequence to sequence(Enoder-Decoder) Model implementation for Machine TransLation.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pyiB7RREZVa3",
    "outputId": "fa6503f2-dfab-4600-96e3-03cd4c659873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P6WL2mk6aBgU",
    "outputId": "791e887f-4c25-498d-b761-ab655630cadb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/MyDrive/1. My_folder/Seq_model/ita-eng.zip\n",
      "  inflating: ita.txt                 \n",
      "  inflating: _about.txt              \n"
     ]
    }
   ],
   "source": [
    "! unzip \"/content/drive/MyDrive/1. My_folder/Seq_model/ita-eng.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3k_AlAuKJqVA"
   },
   "source": [
    "### <font color='blue'>**Loading and Preprocessing the data From original data file.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fU80Ao-AGaob"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5GFjXNKY6LR",
    "outputId": "41a3151a-e6d9-49a0-87e3-d2ef72347815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data is : (343813, 2)\n"
     ]
    }
   ],
   "source": [
    "with open(\"/content/ita.txt\", 'r', encoding=\"utf8\") as f:\n",
    "    eng=[]\n",
    "    ita=[]\n",
    "    for i in f.readlines():\n",
    "        eng.append(i.split(\"\\t\")[0])\n",
    "        ita.append(i.split(\"\\t\")[1])\n",
    "data = pd.DataFrame(data=list(zip(eng, ita)), columns=['english','italian'])\n",
    "print(\"Shape of data is :\",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "edG-UutjY6LT",
    "outputId": "9f957ed2-abcf-426e-dce7-ae59342d5d9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Ciao!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corri!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corra!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Correte!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Chi?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english   italian\n",
       "0     Hi.     Ciao!\n",
       "1    Run!    Corri!\n",
       "2    Run!    Corra!\n",
       "3    Run!  Correte!\n",
       "4    Who?      Chi?"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "jVeTedwxY6LU",
    "outputId": "adb82048-463c-40d8-decf-b7679642b121"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi</td>\n",
       "      <td>ciao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run</td>\n",
       "      <td>corri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run</td>\n",
       "      <td>corra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run</td>\n",
       "      <td>correte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who</td>\n",
       "      <td>chi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english  italian\n",
       "0      hi     ciao\n",
       "1     run    corri\n",
       "2     run    corra\n",
       "3     run  correte\n",
       "4     who      chi"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decontractions(phrase):\n",
    "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
    "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "\n",
    "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "\n",
    "    return phrase\n",
    "\n",
    "def preprocess(text):\n",
    "    # convert all the text into lower letters\n",
    "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
    "    # remove all the spacial characters: except space ' '\n",
    "    text = text.lower()\n",
    "    text = decontractions(text)\n",
    "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_ita(text):\n",
    "    # convert all the text into lower letters\n",
    "    # remove the words betweent brakets ()\n",
    "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
    "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
    "    # we have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
    "    # you are free to do more proprocessing\n",
    "    # note that the model will learn better with better preprocessed data \n",
    "    \n",
    "    text = text.lower()\n",
    "    text = decontractions(text)\n",
    "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
    "    text = re.sub('\\u200b', ' ', text)\n",
    "    text = re.sub('\\xa0', ' ', text)\n",
    "    text = re.sub('-', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "data['english'] = data['english'].apply(preprocess)\n",
    "data['italian'] = data['italian'].apply(preprocess_ita)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "qoKRAKiWY6LV",
    "outputId": "8b8483ac-ba46-40ca-8a42-ce8655a7bf87"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ciao</td>\n",
       "      <td>&lt;start&gt; hi</td>\n",
       "      <td>hi &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corri</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corra</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>correte</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chi</td>\n",
       "      <td>&lt;start&gt; who</td>\n",
       "      <td>who &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   italian  english_inp english_out\n",
       "0     ciao   <start> hi    hi <end>\n",
       "1    corri  <start> run   run <end>\n",
       "2    corra  <start> run   run <end>\n",
       "3  correte  <start> run   run <end>\n",
       "4      chi  <start> who   who <end>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['italian_len'] = data['italian'].str.split().apply(len)\n",
    "data = data[data['italian_len'] < 20]\n",
    "\n",
    "data['english_len'] = data['english'].str.split().apply(len)\n",
    "data = data[data['english_len'] < 20]\n",
    "\n",
    "data['english_inp'] = '<start> ' + data['english'].astype(str)\n",
    "data['english_out'] = data['english'].astype(str) + ' <end>'\n",
    "\n",
    "data = data.drop(['english','italian_len','english_len'], axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "IJlXPNUtY6LW",
    "outputId": "9c53ef97-0196-4604-b74f-f1fcbdde2c03",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>340214</th>\n",
       "      <td>se qualcuno dovesse telefonare dite che torner...</td>\n",
       "      <td>&lt;start&gt; if anyone should phone say i will be b...</td>\n",
       "      <td>if anyone should phone say i will be back at o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65245</th>\n",
       "      <td>tom ha superato i trentanni</td>\n",
       "      <td>&lt;start&gt; tom is past thirty</td>\n",
       "      <td>tom is past thirty &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85450</th>\n",
       "      <td>lavete già venduta</td>\n",
       "      <td>&lt;start&gt; have you sold it yet</td>\n",
       "      <td>have you sold it yet &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138778</th>\n",
       "      <td>tom è un pianista di talento</td>\n",
       "      <td>&lt;start&gt; tom is a gifted pianist</td>\n",
       "      <td>tom is a gifted pianist &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314698</th>\n",
       "      <td>lui gioca a golf due o tre volte al mese</td>\n",
       "      <td>&lt;start&gt; he plays golf two or three times a month</td>\n",
       "      <td>he plays golf two or three times a month &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137891</th>\n",
       "      <td>questa casa è abbandonata</td>\n",
       "      <td>&lt;start&gt; this house is abandoned</td>\n",
       "      <td>this house is abandoned &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28597</th>\n",
       "      <td>ora sono preoccupata</td>\n",
       "      <td>&lt;start&gt; now i am worried</td>\n",
       "      <td>now i am worried &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5613</th>\n",
       "      <td>sono assetato</td>\n",
       "      <td>&lt;start&gt; i am thirsty</td>\n",
       "      <td>i am thirsty &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249775</th>\n",
       "      <td>io ho fatto tre fuoricampo lanno scorso</td>\n",
       "      <td>&lt;start&gt; i hit three home runs last year</td>\n",
       "      <td>i hit three home runs last year &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158056</th>\n",
       "      <td>perché andrei a boston</td>\n",
       "      <td>&lt;start&gt; why would i go to boston</td>\n",
       "      <td>why would i go to boston &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  italian  ...                                        english_out\n",
       "340214  se qualcuno dovesse telefonare dite che torner...  ...  if anyone should phone say i will be back at o...\n",
       "65245                         tom ha superato i trentanni  ...                           tom is past thirty <end>\n",
       "85450                                  lavete già venduta  ...                         have you sold it yet <end>\n",
       "138778                       tom è un pianista di talento  ...                      tom is a gifted pianist <end>\n",
       "314698           lui gioca a golf due o tre volte al mese  ...     he plays golf two or three times a month <end>\n",
       "137891                          questa casa è abbandonata  ...                      this house is abandoned <end>\n",
       "28597                                ora sono preoccupata  ...                             now i am worried <end>\n",
       "5613                                        sono assetato  ...                                 i am thirsty <end>\n",
       "249775            io ho fatto tre fuoricampo lanno scorso  ...              i hit three home runs last year <end>\n",
       "158056                             perché andrei a boston  ...                     why would i go to boston <end>\n",
       "\n",
       "[10 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "E2nWCGVGY6LX"
   },
   "outputs": [],
   "source": [
    "# Saving data so we don't need to perform preprocessing again \n",
    "data.to_csv(\"preprocessed_data.csv\",index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDqx1lkaY6LY"
   },
   "source": [
    "### <font color='blue'>**Loading Preproces data.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QqElB_nKZos",
    "outputId": "845bd553-830e-4474-be72-3f9200f5241b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data is : (343388, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"preprocessed_data.csv\")\n",
    "print(\"Shape of data is :\",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "ng_W5pZVY6La",
    "outputId": "6adc2fb8-9f45-4ed4-debf-630043cfa611"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ciao</td>\n",
       "      <td>&lt;start&gt; hi</td>\n",
       "      <td>hi &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corri</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corra</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  italian  english_inp english_out\n",
       "0    ciao   <start> hi    hi <end>\n",
       "1   corri  <start> run   run <end>\n",
       "2   corra  <start> run   run <end>"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuffsfP4Y6Lb"
   },
   "source": [
    "### <font color='blue'>**Getting Train and Test Data.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v63r-l3dY6Lb",
    "outputId": "931a12cc-65f4-48fa-9b13-ce56d9998247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data is : (274710, 3)\n",
      "Shape of validation data is : (68678, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(data, test_size=0.2)\n",
    "print(\"Shape of train data is :\",train.shape)\n",
    "print(\"Shape of validation data is :\",validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "cekwcCR3Y6Lc"
   },
   "outputs": [],
   "source": [
    "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
    "# with this we can use only one tokenizer for both encoder output and decoder output\n",
    "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'\n",
    "train.iloc[0]['english_out']= str(train.iloc[0]['english_out'])+' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "Mp3JmukgY6Ld",
    "outputId": "c8556103-287c-4d24-af95-db4f17f2aa5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Head :\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231290</th>\n",
       "      <td>non ci saremmo mai dovuti arrendere</td>\n",
       "      <td>&lt;start&gt; we should never have given up &lt;end&gt;</td>\n",
       "      <td>we should never have given up &lt;end&gt; &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113657</th>\n",
       "      <td>vengono forniti servizi per linfanzia</td>\n",
       "      <td>&lt;start&gt; child care is provided</td>\n",
       "      <td>child care is provided &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39725</th>\n",
       "      <td>non sono miei</td>\n",
       "      <td>&lt;start&gt; they are not mine</td>\n",
       "      <td>they are not mine &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      italian  ...                                english_out\n",
       "231290    non ci saremmo mai dovuti arrendere  ...  we should never have given up <end> <end>\n",
       "113657  vengono forniti servizi per linfanzia  ...               child care is provided <end>\n",
       "39725                           non sono miei  ...                    they are not mine <end>\n",
       "\n",
       "[3 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train Data Head :\")\n",
    "print(\"-\"*100)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "g9MC52oGY6Le",
    "outputId": "b1d79494-1dd3-476c-c288-12f6c3dfb6e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Data Head :\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>lho mangiata</td>\n",
       "      <td>&lt;start&gt; i ate it</td>\n",
       "      <td>i ate it &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>vieni presto</td>\n",
       "      <td>&lt;start&gt; come soon</td>\n",
       "      <td>come soon &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>io sono restata</td>\n",
       "      <td>&lt;start&gt; i stayed</td>\n",
       "      <td>i stayed &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              italian        english_inp      english_out\n",
       "711      lho mangiata   <start> i ate it   i ate it <end>\n",
       "1193     vieni presto  <start> come soon  come soon <end>\n",
       "784   io sono restata   <start> i stayed   i stayed <end>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"validation Data Head :\")\n",
    "print(\"-\"*100)\n",
    "validation.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2heRAmDDY6Le"
   },
   "source": [
    "### <font color='blue'>**Creating Tokenizer on the train data and learning vocabulary.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "1W_uhNydY6Lf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "XZVMwtHvY6Lf"
   },
   "outputs": [],
   "source": [
    "tknizer_ita = Tokenizer()\n",
    "tknizer_ita.fit_on_texts(train['italian'].values)\n",
    "encoder_seq = tknizer_ita.texts_to_sequences(train['italian'].values)\n",
    "max_len_ita = 20\n",
    "padded_italian = pad_sequences(encoder_seq, maxlen=max_len_ita, dtype='int32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "WKZgKoy5Y6Lg"
   },
   "outputs": [],
   "source": [
    "# For validation data\n",
    "encoder_seq = tknizer_ita.texts_to_sequences(validation['italian'].values)\n",
    "val_padded_italian = pad_sequences(encoder_seq, maxlen=max_len_ita, dtype='int32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "bQ4hobCmY6Lg"
   },
   "outputs": [],
   "source": [
    "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tknizer_eng.fit_on_texts(train['english_inp'].values)\n",
    "decoder_inp_seq = tknizer_eng.texts_to_sequences(train['english_inp'].values)\n",
    "max_len_eng = 20\n",
    "padded_input_english = pad_sequences(decoder_inp_seq, maxlen=max_len_eng, dtype='int32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "fbXrUl_TY6Lh"
   },
   "outputs": [],
   "source": [
    "# For validation data\n",
    "seq = tknizer_eng.texts_to_sequences(validation['english_inp'].values)\n",
    "val_padded_input_english = pad_sequences(seq, maxlen=max_len_eng, dtype='int32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "NVD3-80RY6Li"
   },
   "outputs": [],
   "source": [
    "# For Decoder_output\n",
    "decoder_out_seq = tknizer_eng.texts_to_sequences(train['english_out'].values)\n",
    "padded_output_english = pad_sequences(decoder_out_seq, maxlen=max_len_eng, dtype='int32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "211fPnE3Y6Li"
   },
   "outputs": [],
   "source": [
    "# For validation data\n",
    "seq = tknizer_eng.texts_to_sequences(validation['english_out'].values)\n",
    "val_padded_output_english = pad_sequences(seq, maxlen=max_len_eng, dtype='int32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KrNa9ZVbY6Lj",
    "outputId": "e47b3bc2-0015-412e-ed4d-1392602b86da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size of Italian Sentences is : 26219\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Vocab size of English Sentences is : 12852\n"
     ]
    }
   ],
   "source": [
    "vocab_size_ita=len(tknizer_ita.word_index.keys())+1\n",
    "print(\"Vocab size of Italian Sentences is :\",vocab_size_ita)\n",
    "vocab_size_eng=len(tknizer_eng.word_index.keys())+1\n",
    "print(\"-\"*100)\n",
    "print(\"Vocab size of English Sentences is :\",vocab_size_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxa1tVOGY6Lk",
    "outputId": "d4ecff4c-4760-4130-9780-2d4f7d1f894c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of Start token in english is : 1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Index of end token in english is : 10106\n"
     ]
    }
   ],
   "source": [
    "start_word_index = tknizer_eng.word_index['<start>']\n",
    "print(\"Index of Start token in english is :\",start_word_index)\n",
    "print(\"-\"*100)\n",
    "end_word_index = tknizer_eng.word_index['<end>']\n",
    "print(\"Index of end token in english is :\",end_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "bS11jAduY6Ll"
   },
   "outputs": [],
   "source": [
    "eng_index_to_word={}\n",
    "for key,value in tknizer_eng.word_index.items():\n",
    "    eng_index_to_word[value]=key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aO6DCMSEY6Lm",
    "outputId": "9fa8ffbc-480b-434f-e53b-c0b1fb6e51e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274710, 20)"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_italian.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xI5prDIZY6Ln",
    "outputId": "95ae0bb0-134c-47e9-aae2-e690a1648e60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274710, 20)"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_english.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XNz4eshaY6Ln",
    "outputId": "7c5efcaf-5b9e-4ec0-b453-99e4c391129e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274710, 20)"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_output_english.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8RDrP4xKabR"
   },
   "source": [
    "## <font color='blue'>**Implementing custom encoder Layer**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "5qDw9aVTY6Lo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "9cex2XfCLOew"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "        super().__init__()\n",
    "        self.lstm_output = 0\n",
    "        self.lstm_state_h=0\n",
    "        self.lstm_state_c=0\n",
    "        self.lstm_size = lstm_size\n",
    "        #Initialize Embedding layer\n",
    "        self.embedding = Embedding(input_dim = inp_vocab_size, output_dim = embedding_size,\n",
    "                                   input_length = input_length,\n",
    "                                   mask_zero=True, name=\"embedding_layer_encoder\")\n",
    "        #Intialize Encoder LSTM layer\n",
    "        self.lstm = LSTM(lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "        \n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "          returns -- encoder_output, last time step's hidden and cell state\n",
    "        '''\n",
    "        \n",
    "        input_embedd = self.embedding(input_sequence)\n",
    "        \n",
    "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd)\n",
    "        \n",
    "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "\n",
    "        return (tf.zeros([batch_size, self.lstm_size]),\n",
    "              tf.zeros([batch_size, self.lstm_size]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>**Implementing custom Decoder Layer**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "x1ES1-sJLOe4"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
    "        super().__init__()\n",
    "        self.vocab_size = out_vocab_size\n",
    "        self.embedding_dim = embedding_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.input_length = input_length\n",
    "        \n",
    "        #Initialize Embedding layer\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim,\n",
    "                                   input_length=self.input_length,\n",
    "                                   mask_zero=True, name=\"embedding_layer_decoder\")\n",
    "        \n",
    "        #Intialize Decoder LSTM layer\n",
    "        self.lstm = LSTM(self.lstm_size, return_sequences=True, return_state=True, name=\"Encoder_LSTM\")\n",
    "        \n",
    "        \n",
    "    def call(self,input_sequence,initial_states):\n",
    "\n",
    "        target_embedd                           = self.embedding(input_sequence)\n",
    "        lstm_output, decoder_h,decoder_c        = self.lstm(target_embedd, initial_state = initial_states)\n",
    "        \n",
    "        return lstm_output,decoder_h,decoder_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>**Implementing custom Encoder-Decoder Model.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "BXrIj4scLOe_"
   },
   "outputs": [],
   "source": [
    "class Encoder_decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,encoder_inputs_length,decoder_inputs_length,output_vocab_size,vocab_size_ita,vocab_size_eng):\n",
    "        super().__init__()\n",
    "        self.vocab_size_ita = vocab_size_ita\n",
    "        self.encoder_inputs_length = encoder_inputs_length\n",
    "        self.vocab_size_eng = vocab_size_eng\n",
    "        self.decoder_inputs_length = decoder_inputs_length\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        #Create encoder object\n",
    "        self.encoder = Encoder(inp_vocab_size=self.vocab_size_ita, embedding_size=100 , lstm_size = 256 ,\n",
    "                               input_length=self.encoder_inputs_length)\n",
    "        \n",
    "        #Create decoder object\n",
    "        self.decoder = Decoder(out_vocab_size=self.vocab_size_eng , embedding_size=100, lstm_size = 256 ,\n",
    "                               input_length=self.decoder_inputs_length)\n",
    "        \n",
    "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
    "        self.dense   = Dense(self.output_vocab_size, activation='softmax')\n",
    "    \n",
    "    def call(self,data):\n",
    "\n",
    "        input,output = data[0], data[1]\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input,0)\n",
    "        states = [encoder_h, encoder_c]\n",
    "        decoder_output ,decoder_h,decoder_c  = self.decoder(output, states)\n",
    "        output                               = self.dense(decoder_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "kcL61dJXLOfB"
   },
   "outputs": [],
   "source": [
    "#Create an object of encoder_decoder Model class, \n",
    "model  = Encoder_decoder(encoder_inputs_length=20,decoder_inputs_length=20,\n",
    "                         output_vocab_size=vocab_size_eng,\n",
    "                         vocab_size_ita = vocab_size_ita,vocab_size_eng= vocab_size_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "zpW-rp3zY6Lt"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ut62gvaY6Lt",
    "outputId": "2b34437b-cd88-4e99-9279-917fa71aa70c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17170/17170 [==============================] - 715s 41ms/step - loss: 1.1624 - val_loss: 0.4817\n",
      "Epoch 2/10\n",
      "17170/17170 [==============================] - 704s 41ms/step - loss: 0.3874 - val_loss: 0.3040\n",
      "Epoch 3/10\n",
      "17170/17170 [==============================] - 694s 40ms/step - loss: 0.2249 - val_loss: 0.2447\n",
      "Epoch 4/10\n",
      "17170/17170 [==============================] - 687s 40ms/step - loss: 0.1573 - val_loss: 0.2205\n",
      "Epoch 5/10\n",
      "17170/17170 [==============================] - 687s 40ms/step - loss: 0.1198 - val_loss: 0.2051\n",
      "Epoch 6/10\n",
      "17170/17170 [==============================] - 693s 40ms/step - loss: 0.0975 - val_loss: 0.1979\n",
      "Epoch 7/10\n",
      "17170/17170 [==============================] - 708s 41ms/step - loss: 0.0814 - val_loss: 0.1947\n",
      "Epoch 8/10\n",
      "17170/17170 [==============================] - 707s 41ms/step - loss: 0.0706 - val_loss: 0.1926\n",
      "Epoch 9/10\n",
      "17170/17170 [==============================] - 704s 41ms/step - loss: 0.0622 - val_loss: 0.1932\n",
      "Epoch 10/10\n",
      "17170/17170 [==============================] - 705s 41ms/step - loss: 0.0564 - val_loss: 0.1934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc0738dc9e8>"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([padded_italian, padded_input_english], padded_output_english ,\n",
    "          epochs = 10,\n",
    "          validation_data = ([val_padded_italian,val_padded_input_english],val_padded_output_english),\n",
    "          verbose = True,\n",
    "          batch_size = 16 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks For Coming.!! :)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sequence_to_Sequence_Models_Assignment_By_Utkarsh_Parashar.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
